---
title: "Let's metabaR-F!"
author: "Boyer F., Benoiston A., Donald J., Lionnet C., Zinger L."
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Let's metabaR-F}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
bibliography: metabaRF.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

![](../metabaRF.png){width=100%}

##Introduction

`metabaR-F` is an R package which supports the importing, handling and post-bioinformatics evaluation and improvement of metabarcoding data quality. It provides a suite of functions to reveal and filter common molecular artifacts produced during the experimental workflow. 

Due to its simple structure, `metabaR-F` can easily be used in combination with other R packages commonly used for ecological analysis (`vegan`, `ade4`, `ape`, `picante`, etc.). In addition, it provides flexible graphical systems using `ggplot2` to vizualize data from both an ecological and experimental perspective.

##Dependencies and Installation

MetabaR-F relies on basic R functions and data structures so as to maximize fexibility and transposability across other packages. It has a minimal number of dependencies to essential R packages :    

- `ggplot2` and `cowplot` for vizualization purposes
- `reshape2` for data manipulation purposes   
- `vegan` for basic data analyses   
- `seqinr` for handling sequence data       
- <span style="color:mediumseagreen"> LZ:... more?</span>

To install `metabaR-F`, use : 

```{r install, eval=FALSE}
install.packages("devtools")
devtools::install_github("metabaRfactory/metabaRffe")
```

And then load the package   
```{r loadpackage}
library(metabaRffe) # modify the name once we'll all agree on that
```

##Package overview

![MetabarF over](../metabaRF_overview.png){width=90%}

<span style="color:mediumseagreen"> LZ: --- could include a section here with a figure showing the different steps of data production and to what the different terms we use (e.g. a pcr, a biological sample, a MOTU, a read, tag, primers, etc.) corresponds </span>   

###Data format and structure

The basic dataformat used in `metabaR-F` is a `metabarlist`, consisting of a list of four tables:   

- `reads`: a `matrix` consisting of PCRs as rows, and molecular operational taxonomic units (MOTUs) as columns. The number of reads for MOTUs are given in each cell, with 0 corresponding to no reads.   

- `motus`: a `data.frame` where MOTUs are listed as rows, and their attributes as columns. Examples of attributes include taxonomic information, but could also include any information collected during bioinformatic analysis. A mandatory field in this table is "sequence", i.e. the DNA sequence representative of the MOTU.    

- `pcrs`: a `data.frame` consisting of PCRs as rows, and PCR attributes as columns. This table is particularly important in `metabaR-F`, as it contains all the information related to the sequencing/pcr protocols and design that are necessary to assess and improve the quality of metabarcoding data [@taberlet2018environmental; @zinger2019dna]. This table can also include information related to the PCR design, such as the tag combinations, the primers used, the well and plate of each PCR, etc. Mandatory fields are:    
    - `sample_id`: a vector indicating the biological sample origin of each PCR
    - `type` : type of pcr between an amplification of a sample or of an experimental control. Only two values allowed: `"sample"` or `"control"`.     
    - `control_type` : type of controls. Mandatory values are listed below and should be attributed as follows:   
        - `NA` if `type="sample"`, i.e. for any pcr amplification of a biological sample.    
        - `"extraction"` for DNA extraction negative controls, i.e. pcr amplification of an extraction where sample was replaced by extraction buffer.   
        - `"pcr"` for PCR negative controls, i.e. pcr amplification where the DNA template was replaced by pcr buffer or sterile water.    
        - `"sequencing"` for sequencing negative controls, i.e. sequencing reads present in the data and that were assigned to unused tag/library index combinations.     
        - `"positive"` for DNA extraction or PCR positive controls, i.e. pcr amplifications of known biological samples or DNA template (e.g. mock community).     

- `samples`: a `data.frame` consisting of biological samples as rows, and associated contextual information as columns. Such information includes e.g. geographic coordinates, abiotic parameters, treatment, etc. This table does not include information on the DNA metabarcoding experimental controls, which can only be found in `pcrs`.


###Function Types 

`metabaR-F` provides a range of function types:

- Import and formating functions to import DNA metabarcoding data from common bioinformatic pipelines (OBITools, <span style="color:mediumseagreen">more to come</span>) or more generally to any data formatted into 4 tables corresponding to the `reads`, `motus`, `pcrs`, `samples` mentionned above.   
- Functions for data curation. These are often absent from most bioinformatic pipelines, as they aim at detecting and allow the tagging potential molecular artifacts such as contaminants or dysfynctional pcrs.    
- Functions for visualizing the data under both ecological (e.g. type of samples) and experimental (e.g. type of controls, distribution across the PCR plate design) perspectives.     
- Functions to manipulate the `metabarlist` object, such as selection of a subset, or data aggregation.   
- <span style="color:mediumseagreen">LZ: Blablabla</span>


###Example dataset

An example data set is provided to show how the package can be used to assess and improve the data quality.  

The `soil_euk` dataset is a `metabarlist`. The data were obtained from an environmental DNA (eDNA) metabarcoding experiment aiming to assess the diversity of soil eukaryotes in French Guiana in two sites corresponding to two contrasting habitats:    
- Mana, a site located in a white sand forest, characterized by highly oligotrophic soils and tree species adapted to the harsh local conditions.    
- Petit Plateau, a site located in the pristine rainforest of the Nouragues natural reserve characterized by *terra firme* soils richer in clay and organic matter. 

![](soil_euk_loc.png){width=50%} ![](soil_euk_plots.png){width=36%}

At each site sample collection were conducted at 16 sampling points separated from one another by 20 m and arranged in a grid across a 1 ha plot. At each sampling point, two types of environmental matrix were sampled: soil and litter. One soil sample corresponds to a composite sample of five soil cores. One litter sample corresponds to ca. 1 m2 of litter collected from the forest floor. A total of 64 DNA extracts (i.e. 16 sampling points x 2 sites x 2 types of environmental matrix, i.e. soil and litter) were thus produced, in addition to four DNA extraction controls (one per site and environmental matrix).
 
For each DNA extract, a short region of the 18S rRNA [using the primer pair Euka02 in @taberlet2018environmental] was amplified by PCR in quadruplicate, following the protocol described in @zinger2019body. The resulting amplicons were pooled and sequenced on an Illumina HiSeq platform, using paired-end technology.
 
The total experiment hence resulted in 384 amplicons as follows:

- 256 pcrs corresponding to biological samples (16 sampling points x 2 sites x 2 environmental matrices x 4 pcr replicates).    
- 16 pcrs corresponding to extraction negative controls (4 extraction negative controls x 4 pcr replicates).    
- 32 pcrs corresponding to PCR negative controls (8 pcr negative controls x 4 pcr replicates).    
- 48 sequencing negative controls (monitoring of 48 unused tag combinations).    
- 32 positive controls obtained from a DNA template composed of a mix of 16 plant species (8 pcr positive controls at different dilutions x 4 pcr replicates).   

 <span style="color:mediumseagreen"> LZ -- We might need to include a description of the PCR plate design here too, not everyone is used to this kind of approach </span> 

The retrieved data were then processed using the OBITools [@boyer:2016:00] and SUMACLUST [@mercier:2013:00] packages. Briefly, paired-end reads were assembled, assigned to their respective samples/marker and dereplicated. Low-quality sequences (containing Ns, shorter than 50 bp or singletons) were excluded. The remaining sequences were clustered into molecular operational taxonomic units (MOTUs) using SUMACLUST at a sequence similarity threshold of 97%. The representative sequence of each motu (i.e. the most abundant sequence) was assigned a taxonomic clade using a database built from the EMBL (release 136) with the ecoPCR program [@Ficetola:2010:00].

<span style="color:mediumseagreen"> LZ -- not sure here that we need to explain everything, this is just a copy paste from the help page, we might need to lighten this document a bit. See also depending on what the pkgdown package offers for this </span>

This description can also be found in the `soil_euk` help page: 

```{r help}
?soil_euk
```

The example dataset is loaded in R as follows: 

```{r soil_euk_data}
data(soil_euk) 
summary_metabarlist(soil_euk)
```

Function `summary_metabarlist` display the dataset dimensions and characteristics: it is composed of 12647 eukaryote MOTUs from 384 pcrs, corresponding to a total of 64 soil cores and the different experimental controls (object `soil_euk$dataset_dimension`. This is why the number of total MOTUs and reads differ in the `soil_euk$dataset_statistics` object when considering all pcrs - which include experimental controls - and all samples, which only includes biological samples.    
This dataset also contains several information relative to MOTUs (15 variables in the `motus` table), PCRs (11 variables in the `pcrs` table), and samples (8 variables in the `samples` table).   

Such information can be observed with basic R commands, given that the `metabarlist` object is a simple R `list`:  

```{r namesex1}
colnames(soil_euk$pcrs)
```

In `soil_euk$pcrs` these columns correspond to:   
- `"plate_no"`: the PCR plate number in which each pcr has been conducted.   
- `"plate_col"` and `"plate_row"`: the well coordinate (i.e. column and row) in which each pcr has been conducted.    
- `"tag_fwd"` and `"tag_rev"`: the forward and reverse nucleotidic tag/indices used to differenciate each pcr.    
- `"primer_fwd"` and `"primer_rev"`: the forward and reverse primers used to conducted the PCR amplification.   
- `"project"`: the project name of the experiment. <span style="color:mediumseagreen"> LZ -- we might consider removing that one </span>    
- `"sample_id"`, `"type"`, `"control_type"`: the mandatory fields for the `pcrs` table that are described above.   


```{r namesex2}
colnames(soil_euk$samples)
```

In `soil_euk$samples` these columns correspond to:   
- `"site_id"` and `"point_id"`: the identification codes for sites and sampling points respectively.    
- `"Latitude"` and `"Longitude"`: the geographic coordinates of the sampling points (decimal degree).    
- `"Code.Petit.Plateau"`: code specific to the experiment, to not be considered here. <span style="color:mediumseagreen"> LZ -- we might consider removing that one </span>   
- `"Site"` `"Habitat"`: sites names and corresponding habitats of each biological sample.   
- `"Material"`: type of environmental matrix for each biological sample.        


##Example analysis with the `soil_euk` dataset

###Data import

`metabaR-F` provides import tools for different data formats. Let's consider for example a suite of four basic ".txt" or csv files each corresponding to the future `reads`, `motus`, `pcrs`, and `samples` objects. These can be imported and formated into a `metabarlist` with the `tabfiles_to_metabarlist` function as follows: 

```{r import, eval=F}
soil_euk <- tabfiles_to_metabarlist(file_reads = "litiere_euk_reads.txt",
                                    file_motus = "litiere_euk_motus.txt",
                                    file_pcrs = "litiere_euk_pcrs.txt",
                                    file_samples = "litiere_euk_samples.txt")
```

Default field separator of the input files is tabulation, but can be modified by the user. The rows x columns of the input files should correspond to the objects expected in the table `reads` (i.e. pcrs x motus), `motus` (i.e. motus x motus characteristics), `pcrs` (i.e. pcrs x pcrs characteristics), and `samples` (i.e. samples x samples characteristics). Note that in the example above, these files are stored in the current working directory.    

###Diagnostic Plots

Before processing the data *per se*, it is useful to begin the analysis with an explorative vizualization of the raw data, which can already highlight several potential problems. 

####Basic vizualisation

A first basic assessment can consist in determining how many reads and MOTUs have been obtained across the different samples and control types, as one can confidently expect that negative controls yield no or much smaller amounts of reads and MOTUs. To do so, one can either create new independant vectors storing the total number of reads and MOTUs, or store these information in the table `pcrs` directly, as done below, the `pcrs` table being a R `data.frame`...

```{r diag1_readsmotus}
#compute the number of reads per pcr
soil_euk$pcrs$nb_reads <- rowSums(soil_euk$reads)
#compute the number of motus per pcr
soil_euk$pcrs$nb_motus <- rowSums(soil_euk$reads>0)
```

... and then plot the results using the "control_type" column of the `pcrs` table

```{r diag1_boxplotreadsmotus, warning=F, message=F, fig.width=7, fig.height=4}
#load requested package for plotting
library(ggplot2)
library(reshape2)

#create an input table (named check1) for ggplot of 3 columns: 
#  (i) control type 
#  (ii) a vector indicated whether it corresponds to nb_reads or nb_motus, 
#  (iii) the corresponding values.

check1 <- melt(soil_euk$pcrs[,c("control_type", "nb_reads", "nb_motus")])

ggplot(data <- check1, aes(x=control_type, y=value, color=control_type)) + 
  geom_boxplot() + theme_bw() + 
  geom_jitter(alpha=0.2) + 
  scale_color_manual(values = c("brown", "red", "cyan4","pink"), na.value = "darkgrey") +
  facet_wrap(~variable, scales = "free_y") + 
  theme(axis.text.x = element_text(angle=45, h=1))
```

Remember that pcrs obtained from biological samples are referred to `NA` in the `control_type` vector, they are exhibited in grey in the example above. Contrary to our expectations, we observe that extraction and pcr negative controls yielded a small amount of MOTUs of non negligible abundance, which likely correspond to contaminations. No worries for now, this feature is relatively common in DNA metabarcoding datasets [@taberlet2018environmental; @zinger2019dna].   

An other basic vizualization consists in determining how the number of MOTUs and reads correlate. This information can help identify the sequencing depth below which a PCR might not be reliable, in particular by comparison with experimental negative controls' behavior.     

```{r diag2_readsMOTUs, message=F, warning=F, fig.width=5, fig.height=4}
#Using the nb_reads and nb_motus defined previously in the soil_euk$pcrs table
ggplot(soil_euk$pcrs, aes(x=nb_reads, y=nb_motus, color = control_type)) + 
  geom_point() + theme_bw() + 
  scale_y_log10() + scale_x_log10() + 
  scale_color_manual(values = c("brown", "red", "cyan4","pink"), na.value = "darkgrey")
```

In general, the plot demonstrates a positive correlation between the number of reads and of MOTUs per pcr. The strength of the relationship for the different samples and controls can provide several informations. A high correlation suggests that the sequencing effort is not sufficient to cover the whole pcr diversity. On the contrary, an absence of correlation suggests that the diversity is well covered by sequencing. The latter is exemplified here with the pcr and extraction negative controls that harbor high number of reads, and correspond to the amplification of a few contaminants. At the opposite, the relationship is the steepest for sequencing negative controls, which reflects that albeit this bias do occur at low rates it occurs for many MOTUs [@schnell:2015:00]. For pcrs obtained from biological samples, the number of reads and motus tends to be correlated. <span style="color:mediumseagreen"> LZ: --- Maybe to reformulate here... not super easy to explain </span>

####Vizualisation in the PCR design context

Another way to vizualise these basic descriptive dataset statistics is to represent them in their experimental context, e.g. by plotting the number of reads in the PCR plates, provided that the pcrs plates numbers and well have been well provided in the `pcrs` table. Such vizualisation can highlight potential issues which may have occured during the PCR amplification. For example, low read abundances in real samples throughout one line or column of the PCR plate could mean that a primer was dysfunctional or that the pipetting of reagents was inconsistent throughout the plate, resulting in low amplicon yields. Let's see how it appears for the `soil_euk` data:   

```{r ggpcrplate1, warning=F, message=F, fig.width=7, fig.height=5}
ggpcrplate(soil_euk, FUN = function(m){rowSums(m$reads)}, legend_title = "# of reads per PCR")
```

The `ggpcrplate` function uses a `metabarlist` and a function to apply to the table `reads` of that metabarlist. The commandline above computes the number of reads per PCR and display these in their PCR plate context. This operation is the default when using this function, and can be obtained with the basic call as below.

```{r ggpcrplate2, warning=F, message=F, fig.width=7, fig.height=5, eval=F}
ggpcrplate(soil_euk)
```

Besides the presence of apparent contaminants extraction and pcr negative controls, one can observe:    
- That sequencing negative controls (here corresponding to wells where neither DNA template nor PCR reagents were intrudced, hence corresponding to unused tag combinations in this particular experimental design), have low or null read numbers. This exemplifies the existence of the so called "tagjumps" [@schnell:2015:00; reviewed in @zinger2019dna], which remain relatively limited in this experiment.   
- That certain lines or columns do exhibit a low number of reads in general, e.g. here in all wells in plate 1, line H. This tendancy might denote a pipetting or primer problem, as mentionned above.  

If the PCR design uses a combination of tags as for the example dataset (i.e. 2 different tags in the 5' of each PCR primer), and that this information is available in the `pcrs` table, it is possible to determine if one of the tag introduces systematic biases in PCR amplicon yields as follows: 

```{r ggpcrtag, warning=F, message=F, fig.width=7, fig.height=7}
#Here the list of all tag/indices used in the experiment is available in the column "tag_rev" of the soil_euk$pcrs table
tag.list <- as.character(unique(soil_euk$pcrs$tag_rev))
ggpcrtag(soil_euk, legend_title = "# of reads per PCR", FUN = function(m) {rowSums(m$reads)},
                     taglist = tag.list) 
```

Function `ggpcrtag` works similarly to `ggpcrplate`. The plot shows the number of reads in their full PCR design, i.e. with all plates all together including the tags they may share. The boxplots above and to the right show the distribution of the number of reads obtained for each tag-primer. Although this vizualisation is equivalent to the one produced with `ggpcrplate`, it can prove useful when looking for tags which may yield low read numbers in larger scale experiments. <span style="color:darkturquoise"> ASB -- j'ajouterais une graduation sur l'ordonn√©e des boxplots </span>

####Vizualisation with tools borrowed from ecology

Another useful way to vizualize the success of the experiment consists in constructing rarefaction curves, which can indicate whether the diversity in MOTUs of each pcr has been well sampled by sequencing (remember that sequencing is a sampling process.. of amplicons).    

In `metabaR-F`, rarefaction curves are constructed with different diversity indices, not only for richness. These indices are part of the Hill numbers framework [reviewed in @chao2014unifying], which is based on the concept of effective number species, and is defined as follows: 

$^{q}D=(\sum_{i=1}^{S}p_i^q)^{1/(1-q)}$     

Where $S$ is the total number of species, and $p_i$ the species frequency. The diversity $^{q}D$ measured here correspond to the diversity of equally-common species. The order $q$ defines the degree of species commonness. In other words, it give more or less weight to rare species. The interesting feature of the framework is that it unifies mathematically the best known diversity measures in ecology through this unique parameter $q$:    
for $q=0$, $^{0}D$ is species richness     
for $q=1$, $^{1}D$ approaches the exponential of the Shannon index $H'=\sum_{i=1}^{S}p_i log p_i$    
for $q=2$, $^{2}D$ is the inverted of the Simpson index $\lambda=\sum_{i=1}^{S}p_i^2$    
Which are the value of $q$ for which `metabaR-F` will construct rarefaction curves.

The rationale for using these different indices for metabarcoding data is to give more or less weight to rare MOTUs that can correspond to molecular artifacts and lead to spurious ecological conclusions [@taberlet2018environmental; @alberdi:2019:00; @calderon2020environmental].

`metabaR-F` also compute the Good's coverage index for each pcr:   
$Coverage = 1-\frac{N_{singletons}}{N}$    
Where $N_{singletons}$ is the number of singletons and $N$ the total number of individuals. In other words, it corresponds to percentage of reads that are not singletons in the pcr. Note that this latter index should be interpreted carefully, as it is based on singletons, knowing that "absolute singeltons" (i.e. singeltons across the whole sequence dataset) are often filtered during the bioinformatic process.

Since this process can take a while, we here only construct rarefaction curves for a subset of pcrs, in this case by keeping only few samples from the H20 plot of the Petit Plateau. The subsetting can be done as follows:  

```{r subset, message=F, warning=F}
#get the samples names from the H20 plot
h20_id <- grepl("H20-[A-B]", rownames(soil_euk$pcrs))

#subset the data
soil_euk_h20 <- subset_metabarlist(soil_euk, table = "pcrs", indices = h20_id)

#check results
summary_metabarlist(soil_euk_h20)
```

Note that subsetting of the `metabarlist` can be done with `subset_metabarlist` with any criterion, based either on MOTUs, PCRs, or sample characteristics.  

Now lets construct the rarefaction curves with the `hill_rarefaction` function for different sequencing depths. The number of sequencing depths considered is defined by the `nsteps` argument. For each sequencing depth, the `reads` table is resampled randomly `nboot` times so that to obtain an estimate of $^{q}D$ and $Coverage$. `nboot` is low in the example below to limit the computing time.

```{r hillraref, message=F, warning=F}
soil_euk_h20.raref = hill_rarefaction(soil_euk_h20, nboot = 20, nsteps = 10)
head(soil_euk_h20.raref$hill_table)
```

The `hill_rarefaction` function produces an object from which the first element is a table indicating the `pcr_id`, the sequencing depth at which the PCR was resampled, and the corresponding diversity / coverage indices. These can now be used to draw rarefaction curves.

```{r gghill, message=F, warning=F, fig.width=7, fig.height=2.5}
gghill_rarefaction(soil_euk_h20.raref) 
```

The user may also want to differenciate different types of samples, for example here soil vs. litter samples. This can be achieved as follows:   

```{r gghill2, message=F, warning=F, fig.width=7, fig.height=3}
#define a vector containing the Material info for each pcrs 
material <- soil_euk_h20$samples$Material[match(soil_euk_h20$pcrs$sample_id,
                                               rownames(soil_euk_h20$samples))]

#use of gghill_rarefaction requires a vector with named pcrs
material <- setNames(material,rownames(soil_euk_h20$pcrs))

#plot
p <- gghill_rarefaction(soil_euk_h20.raref, group=material)
p + scale_fill_manual(values = c("goldenrod4", "brown4", "grey")) +
    scale_color_manual(values = c("goldenrod4", "brown4", "grey")) +
    labs(color="Material type")
```

The generated curves tell us a couple of things about the pcrs:    
 - The sampling coverage is relatively high even at intermediate sequencing depths.   
 - The less weight is given to rare MOTUs (i.e. the more $q$ is high), the quicker $^{q}D$ is well estimated.  
 - Litter samples in general tend to be less diverse than soil samples    

###Flagging spurious signal   

The next steps of the analysis usually consists at spotting potential spurious signal, whether in terms of MOTUs (e.g. contaminants, presence of untargeted taxa due to primer lack of specificity), MOTUs abundances (i.e. tagjumps), or pcrs (pcrs yielding low amounts of reads or with low replicability). 

####Detecting contaminants based on experimental negative controls

Contamination can occur at multiple stages, from sample collection to library preparation. Detecting these contaminants can be done through the use of control samples at each stage [reviewed in @taberlet2018environmental; @zinger2019dna], as is the case for the `soil_euk` dataset. Due to the tagjump bias, many genuine MOTUs that dominate biological samples can be detected in negative controls. Consequently, simply removing from the dataset any MOTU that occur in negative controls is a very bad idea.

In negative controls, a contaminant should be preferentially amplified since there is no competing DNA. The function `contaslayer` relies on this assumption and detects MOTUs whose relative abundance across the whole dataset is maximum in negative controls. The `contaslayer` function produces a vector of MOTUs names that can be used to flag those MOTUs, making their removal possible at subsequent stages. **Note however that this approach won't be apropriate if the negative controls have been contaminated with biological samples.** Below, an example for detecting contaminants from the DNA extraction step.

```{r contaslayer, message=F, warning=F, fig.width=6, fig.height=3}
#Define a vector containing the extraction negative control names
ext.controls <- rownames(soil_euk$pcrs)[which(soil_euk$pcrs$control_type=="extraction")]

#now detect contaminants within your metabarlist
conta.ext <- contaslayer(soil_euk, controls = ext.controls)

#tag these sequences in the metabarlist object
soil_euk$motus$flagged_motus <- NA
soil_euk$motus[!conta.ext$motus$not_contamination, "flagged_motus"]  <- "extraction contaminant"
```

Below are the ten most common contaminants that were identified by contaslayer in from `pcr` controls in the `soil_euk` dataset.

```{r contaslayer2, message=F, warning=F, echo=F, fig.width=6, fig.height=3}
library(kableExtra)
dt <- soil_euk$motus[!is.na(soil_euk$motus$flagged_motus), c("count", "best_identity.order_filtered_embl_r136_noenv_EUK", "path", "sequence")]
dt$best_identity.order_filtered_embl_r136_noenv_EUK <- round(dt$best_identity.order_filtered_embl_r136_noenv_EUK )
colnames(dt) <- c("total # reads", "similarity to ref", "full taxonomic path", "sequence")

rownames(dt) <- NULL

kable(dt[order(dt[,1], decreasing = TRUE)[1:10],]) %>%
  kable_styling(bootstrap_options= c("striped", "hover", "condensed"), 
                font_size = 8, full_width = F)
```

The identified contaminants correspond to metazoans (including humans), protists, fungi and plants. The most abundant contaminant does not have precise taxonomic identification here, but a BLAST of the sequence suggests that it corresponds most likely to a *Fusarium*, a notorius laboratory contaminant.   

Next, one may want to know how these contamiants are distributed across the `soil_euk` dataset. For example, the contamination could be present only in one PCR plate for some reasons. This can be achieved using the `ggpcrplate` function introduced earlier, for example for the most common contaminant:

```{r contaslayer3, message=F, warning=F, fig.width=7, fig.height=6}
#Identify the most common contaminant
max.conta <- rownames(conta.ext$motus[which.max(soil_euk$motus[!conta.ext$motus$not_contamination, "count"]),])

#Distribution of the most abundant contaminant in the PCR plate design in terms of relative abundance
ggpcrplate(soil_euk, legend_title = "#reads of most \nabundant contaminant",
           FUN = function(m) {m$reads[, max.conta]/rowSums(m$reads)})
```

In this case, the most abundant contaminant occur across all samples, but in general in low relative abundance (on average `r 100*round(mean(soil_euk$reads[,max.conta]/rowSums(soil_euk$reads+1)),4)` % here, `ggplot` tends to oversize low values). 

One can also determine wether pcrs exhibit generally a high proportions of contaminants.

```{r contaslayer4, message=F, warning=F, fig.width=4, fig.height=3}
#compute relative abundance of all pcr contaminants together 
a <- data.frame(conta.relab = rowSums(soil_euk$reads[,!is.na(soil_euk$motus$flagged_motus)]) / 
                                    rowSums(soil_euk$reads))
#add information on control types
a$control_type <- soil_euk$pcrs$control_type[match(rownames(a), rownames(soil_euk$pcrs))]

ggplot(a, aes(x=control_type, y=conta.relab, color=control_type)) + 
  geom_boxplot() + geom_jitter(alpha=0.5) +
  scale_color_manual(values = c("brown", "red", "cyan4","pink"), na.value = "darkgrey") +
  labs(x=NULL, y="Prop. Reads (log10)") + 
  theme_bw() + 
  scale_y_log10()
```

Overall, samples yield much less amounts of pcr contaminants than experimental negative controls. Some pcrs have 10% of their reads corresponding to contaminants, and could be flagged them as follow.

```{r contaslayer5, message=F, warning=F,  fig.width=4, fig.height=3}
#set a minimum value of total contaminant relative abundance
thresh <- 1e-1
#and flagg
soil_euk$pcrs$flagged_pcrs = ifelse(a$conta.relab[match(rownames(soil_euk$pcrs), rownames(a))]>thresh, 
                             "too much conta pcr", NA)
```

These correspond to `r 100*round(sum(!is.na(soil_euk$pcrs$flagged_pcrs) & soil_euk$pcrs$type=="sample")/sum(soil_euk$pcrs$type=="sample"),4)` % of pcrs obtained for biological samples

<span style="color:mediumseagreen">LZ: See here if we keep that example because it's super arbitrary... And here and in other related plot, should we draw a line representing the threshold chosen?</span>

####Flagging highly degraded or non-target MOTUs

Non-target sequences can be amplified if the primers are not specific enough. On the other hand, some highly degraded sequences can be produced throughout the data production process, such as primer dimers, or chimeras from multiple parents. We can use the MOTU taxonomic asssignements information and similarity scores to identify these. 

Since the `soil_euk` dataset was obtained with primers that primarily targets eukaryotes, bacterial or archeal MOTUs should be excluded.

```{r nontarget, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#Find in the motus table the MOTUs corresponding to non-target taxa
conta.untar <- rownames(soil_euk$motus)[grep("Bacteria|Archaea", soil_euk$motus$path)]
length(conta.untar)
```

Here we find 7 MOTUS which have been identified as Bacteria or Archaea. Since they are not of interest to us, we will flag these. One could consider appending the flags throughout the tagging process so that to ensure that all the information is conserved when deciding removing certain MOTUs or PCRs.

```{r nontarget2, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#tag these sequences in the metabarlist object as non-target
soil_euk$motus[conta.untar, "flagged_motus"] <-
   ifelse(is.na(soil_euk$motus[conta.untar, "flagged_motus"]),"non-target",
                                                   paste(soil_euk$motus[conta.untar, "flagged_motus"], "|",
                                                         "non-target", sep = ""))
soil_euk$motus[conta.untar, "flagged_motus"]
```

In this example, three of the non-target sequences have previously been identified as extraction contaminants. 

Next, we want to identify MOTUS whose sequence is too dissimilar from reference, i.e. that are more likely to be a degraded sequence. In this case, a threshold of similarity should be chosen, and should be representative of how complete the reference database used is likley to be. One way to assess this is to assess the distribution of MOTUs similarities against the reference database. 

```{r nontarget3, message=F, warning=F, cache=T, fig.width=6, fig.height=3}
#Assess the distribution of similarity scores for MOTUs
a <- 
  ggplot(soil_euk$motus, aes(x=best_identity.order_filtered_embl_r136_noenv_EUK)) + 
    geom_histogram(color="grey", fill="white", bins=20) + 
    theme_bw() + 
    theme(panel.grid = element_blank()) + 
    labs(x="% similarity against best match", y="# OTUs")

#Same for reads MOTUs
b <- 
  ggplot(soil_euk$motus, aes(x=best_identity.order_filtered_embl_r136_noenv_EUK, y = ..count.., weight = count)) + 
    geom_histogram(color="grey", fill="white", bins=20) + 
    theme_bw() + 
    theme(panel.grid = element_blank()) + 
    labs(x="% similarity against best match", y="# Reads")

library(cowplot)
ggdraw() + 
  draw_plot(a, x=0, y=0, width = 0.5) + 
  draw_plot(b, x=0.5, y=0, width = 0.5)
```

Here we can consider any MOTU as degraded sequences if it has a sequence similarity < 80% against its best match in the reference database. 

```{r nontarget5, message=F, warning=F, cache=T, fig.width=11, fig.height=6}
conta.degrad <- 
  rownames(soil_euk$motus)[which(soil_euk$motus$best_identity.order_filtered_embl_r136_noenv_EUK<0.8)]
soil_euk$motus$flagged_motus[match(conta.degrad, rownames(soil_euk$motus))] <-
  ifelse(is.na(soil_euk$motus$flagged_motus[match(conta.degrad, rownames(soil_euk$motus))]), "conta degraded",
         paste(soil_euk$motus$flagged_motus[match(conta.degrad, rownames(soil_euk$motus))], "conta degraded",
               sep="|"))
```

In total, these represent `r length(conta.degrad)` MOTUs. These are tagged for removal at a later stage above.

###Lowering tag-jumps

Tagjumps are frequency-dependant, i.e. with this bias abundant genuine MOTUs are more likely to be found in low abundance in samples were they are not supposed to be. To reduce the amount of such false positives, the function `tagumpslayer` consider each OTU separately and set to 0 any abundance below a given threshold, corresponding to a given amount of the total OTU abundance in the entire dataset. Such data a curation strategy is similar to what has been proposed by @esling:2015:00.

<span style="color:mediumseagreen">LZ: Removed the whole thing explaining what are tagjumps. I think that a vignette is not the right place for that. To be discussed</span>

The abundance threshold can be evaluated by testing how this filtration procedure affect basic dataset characteristics (e.g. # MOTUs or reads) at different levels as below.

```{r tagjump1, message=F, warning=F, cache=T, fig.width=7, fig.height=5}
#Define a vector of thresholds to test
thresholds <- c(0,1e-4,1e-3, 1e-2, 3e-2, 5e-2) 

#Run the tests and stores the results in a list
tests <- lapply(thresholds, function(x) tagjumpslayer(soil_euk,x))
names(tests) <- paste("t_", thresholds, sep="")

#Format the data for ggplot with amount of reads at each threshold
tmp <- melt(as.matrix(do.call("rbind", lapply(tests, function(x) rowSums(x$reads)))))
colnames(tmp) <- c("threshold", "sample", "abund_contaout")
#Add richness in MOTUs at each threshold
tmp$rich_contaout <- melt(as.matrix(do.call("rbind", lapply(tests, function(x) {rowSums(x$reads>0)}))))$value
#Add further information
tmp$controls <- soil_euk$pcrs$control_type[match(tmp$sample, rownames(soil_euk$pcrs))]
tmp$threshold <- as.numeric(gsub("t_", "", tmp$threshold))

#New table formatting for ggplot
tmp2 <- melt(tmp, id.vars=colnames(tmp)[-grep("contaout", colnames(tmp))])
tmp2$variable <- ifelse(tmp2$variable=="rich_contaout", "#MOTUs", "#Reads")

ggplot(tmp2, aes(x=as.factor(threshold), y=value)) + 
  geom_boxplot(color="grey40") +
  geom_jitter(aes(color=controls), width = 0.2, alpha=0.5) + 
  scale_color_manual(values = c("brown", "red", "cyan4","pink"), na.value = "darkgrey") +
  facet_wrap(~variable+controls, scale="free_y", ncol=5) + 
  theme_bw() + 
  scale_y_log10() +
  labs(x="rel abundance filtering threshold", y="# Reads/MOTUs") + 
  theme(panel.grid = element_blank(), 
        strip.background = element_blank(), 
        axis.text.x = element_text(angle=40, h=1), 
        legend.position = "none")
```

<span style="color:mediumseagreen">LZ: TO FINISH</span>

##References

